// Copyright 2022 The Cockroach Authors.
//
// Use of this software is governed by the Business Source License
// included in the file licenses/BSL.txt.
//
// As of the Change Date specified in that file, in accordance with
// the Business Source License, use of this software will be governed
// by the Apache License, Version 2.0, included in the file
// licenses/APL.txt.

package persistedsqlstats_test

import (
	"context"
	"fmt"
	"github.com/cockroachdb/cockroach/pkg/sql/sqlstats"
	"strings"
	"testing"
	"time"

	"github.com/cockroachdb/cockroach/pkg/base"
	"github.com/cockroachdb/cockroach/pkg/sql"
	"github.com/cockroachdb/cockroach/pkg/sql/catalog/systemschema"
	"github.com/cockroachdb/cockroach/pkg/sql/sqlstats/persistedsqlstats"
	"github.com/cockroachdb/cockroach/pkg/testutils/serverutils"
	"github.com/cockroachdb/cockroach/pkg/testutils/sqlutils"
	"github.com/cockroachdb/cockroach/pkg/util/leaktest"
	"github.com/cockroachdb/cockroach/pkg/util/log"
	"github.com/cockroachdb/cockroach/pkg/util/timeutil"
	"github.com/stretchr/testify/require"
)

type earliestAggTsTestCase struct {
	tableName      string
	hashColumnName string
	runWithTxn     bool
}

var earliestAggTsTestCases = []earliestAggTsTestCase{
	{
		tableName:      "system.statement_statistics",
		hashColumnName: systemschema.StmtStatsHashColumnName,
		runWithTxn:     false,
	},
	{
		tableName:      "system.transaction_statistics",
		hashColumnName: systemschema.TxnStatsHashColumnName,
		runWithTxn:     true,
	},
}

func TestScanEarliestAggregatedTs(t *testing.T) {
	defer leaktest.AfterTest(t)()
	defer log.Scope(t).Close(t)
	//
	//tableName := "system.statement_statistics"
	//hashColumnName := systemschema.StmtStatsHashColumnName
	//runWithTxn := false

	tableName := "system.transaction_statistics"
	hashColumnName := systemschema.TxnStatsHashColumnName
	runWithTxn := true

	baseTime := timeutil.Now()
	//.Add(5 * time.Second)
	aggInterval := time.Hour

	// chosen to ensure a different truncated aggTs
	advancementInterval := time.Hour * 2

	fakeTime := stubTime{
		aggInterval: aggInterval,
	}
	fakeTime.setTime(baseTime)

	s, db, _ := serverutils.StartServer(t, base.TestServerArgs{
		Knobs: base.TestingKnobs{
			SQLStatsKnobs: &sqlstats.TestingKnobs{
				StubTimeNow: fakeTime.Now,
			},
		},
	})

	//testCluster := serverutils.StartNewTestCluster(t, 3 /* numNodes */, base.TestClusterArgs{
	//	ServerArgs: base.TestServerArgs{
	//		Knobs: base.TestingKnobs{
	//			SQLStatsKnobs: &sqlstats.TestingKnobs{
	//				StubTimeNow: fakeTime.Now,
	//			},
	//		},
	//	},
	//})

	ctx := context.Background()
	defer s.Stopper().Stop(ctx)
	//defer testCluster.Stopper().Stop(ctx)

	sqlStats := s.SQLServer().(*sql.Server).GetSQLStatsProvider().(*persistedsqlstats.PersistedSQLStats)
	sqlConn := sqlutils.MakeSQLRunner(db)
	// set up multiple persisted times, also in-memory

	//for _, tc := range testQueries {
	//	for i := int64(0); i < tc.count; i++ {
	//		sqlConn.Exec(t, tc.query)
	//	}
	//}

	// generate some in-memory stats
	// fewer statements than the number of hash shards, to simulate at least one shard not having anything
	//for i := int64(0); i < 1; i++ {
	//	sqlConn.Exec(t, "SELECT 1")
	//}

	//expectedStmtFingerprints := make(map[string]int64)
	//for _, tc := range testQueries {
	//	expectedStmtFingerprints[tc.fingerprint] = tc.count
	//	for i := int64(0); i < tc.count; i++ {
	//		sqlConn.Exec(t, tc.query)
	//	}
	//}

	truncatedBaseTime := baseTime.Truncate(aggInterval)

	// we haven't run any user queries, but there should be in-memory stats for internal tables
	t.Run("empty persisted stats table", func(t *testing.T) {
		memoryEarliestAggTs, err := sqlStats.ScanEarliestAggregatedTs(ctx, s.InternalExecutor().(*sql.InternalExecutor), tableName, hashColumnName)
		fmt.Println("mem", memoryEarliestAggTs)
		if err != nil {
			t.Fatal(err)
		}
		require.Equal(t, truncatedBaseTime, memoryEarliestAggTs, "expected: %s, got: %s", truncatedBaseTime, memoryEarliestAggTs)

	})

	t.Run("table read", func(t *testing.T) {
		sqlStats.Flush(ctx)

		// normal disk read
		// verify test set up
		verifyDistinctAggregatedTs(t, sqlConn, tableName, []time.Time{truncatedBaseTime})
		diskEarliestAggTs1, err1 := sqlStats.ScanEarliestAggregatedTs(ctx, s.InternalExecutor().(*sql.InternalExecutor), tableName, hashColumnName)
		if err1 != nil {
			t.Fatal(err1)
		}
		require.Equal(t, truncatedBaseTime, diskEarliestAggTs1, "expected: %s, got: %s", truncatedBaseTime, diskEarliestAggTs1)

		// flush again before advancing time, to flush the stats generated by the test itself
		sqlStats.Flush(ctx)

		// run and flush statements at an earlier time, before baseTime
		beforeBaseTime := baseTime.Add(-advancementInterval)
		fmt.Println("before time", beforeBaseTime)
		fakeTime.setTime(beforeBaseTime)
		truncatedBeforeBaseTime := beforeBaseTime.Truncate(aggInterval)

		// generate one single earliest statement
		runStatements(t, sqlConn, 1, runWithTxn)
		//sqlConn.Exec(t, "SELECT 1")
		//for _, tc := range testQueries {
		//	for i := int64(0); i < tc.count; i++ {
		//	}
		//}
		sqlStats.Flush(ctx)

		// run and flush statements at a later time
		afterBaseTime := baseTime.Add(advancementInterval)
		fakeTime.setTime(afterBaseTime)
		//for _, tc := range testQueries {
		//	for i := int64(0); i < tc.count; i++ {
		//		sqlConn.Exec(t, tc.query)
		//	}
		//}

		// generate statements at later times, with different fingerprints so that they get distributed across all shards
		runStatements(t, sqlConn, systemschema.SQLStatsHashShardBucketCount*5, runWithTxn)
		//for i := int64(1); i < systemschema.SQLStatsHashShardBucketCount*5; i++ {
		//	ones := make([]string, i)
		//	for j := 0; j < len(ones); j++ {
		//		ones[j] = "1"
		//	}
		//	stmt := fmt.Sprintf("SELECT %[1]s", strings.Join(ones, ", "))
		//	sqlConn.Exec(t, stmt)
		//}
		sqlStats.Flush(ctx)

		// create in-memory stats for good measure
		// fixme: commented out because 15s flush, not querying in memory
		//if runWithTxn {
		//	sqlConn.Exec(t, "BEGIN; SELECT 1 WHERE 1 < 10; COMMIT;")
		//} else {
		//	sqlConn.Exec(t, "SELECT 1 WHERE 1 < 10")
		//}
		//for _, tc := range testQueries {
		//	for i := int64(0); i < tc.count; i++ {
		//		sqlConn.Exec(t, tc.query)
		//	}
		//}

		// verify test set up
		verifyDistinctAggregatedTs(t, sqlConn, tableName, []time.Time{truncatedBeforeBaseTime, truncatedBaseTime, afterBaseTime.Truncate(aggInterval)})
		verifyNotPresentInAllShards(t, sqlConn, tableName, truncatedBeforeBaseTime)

		//here

		// the earliest aggTs should now be beforeBaseTime
		diskEarliestAggTs2, err2 := sqlStats.ScanEarliestAggregatedTs(ctx, s.InternalExecutor().(*sql.InternalExecutor), tableName, hashColumnName)
		if err2 != nil {
			t.Fatal(err2)
		}
		require.Equal(t, truncatedBeforeBaseTime, diskEarliestAggTs2, "expected: %s, got: %s", truncatedBeforeBaseTime, diskEarliestAggTs2)

		//stmt := fmt.Sprintf(`SELECT count(*) FROM %[1]s WHERE aggregated_ts = $1::TIMESTAMP`,
		//	tableName,
		//)
		//row := sqlConn.QueryRow(t, stmt, truncatedBeforeBaseTime)
		//var count int
		//row.Scan(&count)
		//fmt.Println("here ", count)
		//// there should be two stats at that time: the single query that we ran, and the insert into statement stats
		//// would this change with transaction stats?
		//require.Equal(t, 2, count)
	})

}

func runStatements(
	t *testing.T,
	sqlConn *sqlutils.SQLRunner,
	numStatements int,
	withTxn bool,
) {
	for i := 1; i < numStatements+1; i++ {
		// generate statements with unique fingerprints
		ones := make([]string, i)
		for j := 0; j < len(ones); j++ {
			ones[j] = "1"
		}
		stmt := fmt.Sprintf("SELECT %[1]s", strings.Join(ones, ", "))
		if withTxn {
			stmt = fmt.Sprintf("BEGIN; %[1]s; COMMIT;", stmt)
		}
		fmt.Println("")
		sqlConn.Exec(t, stmt)
	}
}

func verifyDistinctAggregatedTs(
	t *testing.T,
	sqlConn *sqlutils.SQLRunner,
	tableName string,
	sortedExpectedAggregatedTsValues []time.Time,
) {
	// [1]: table name
	// [2]: hash column name
	stmt := fmt.Sprintf(`SELECT DISTINCT aggregated_ts FROM %[1]s ORDER BY aggregated_ts`,
		tableName,
	)
	rows := sqlConn.Query(t, stmt)
	defer rows.Close()
	aggregatedTsValues := []time.Time{}

	for rows.Next() {
		var aggregatedTs time.Time
		if err := rows.Scan(&aggregatedTs); err != nil {
			t.Fatal(err)
		}
		fmt.Println("distinct", aggregatedTs)
		aggregatedTsValues = append(aggregatedTsValues, aggregatedTs)

	}

	require.Equal(t, sortedExpectedAggregatedTsValues, aggregatedTsValues)

}

func verifyNotPresentInAllShards(
	t *testing.T,
	sqlConn *sqlutils.SQLRunner,
	tableName string, aggTs time.Time) {
	// this is a more convenient, though stricted test. if there are fewer stats with that aggTs than shards, then definitely not all shards have a row with that aggTs
	// using this
	// concretely, running a single query/transaction generates two statement statistics (one for itself, and one for inserting the statistic), and one transaction statistic (if it's a transaction)
	stmt := fmt.Sprintf(`SELECT count(*) FROM %[1]s WHERE aggregated_ts = $1::TIMESTAMP`,
		tableName,
	)
	row := sqlConn.QueryRow(t, stmt, aggTs)
	var count int
	row.Scan(&count)
	require.Less(t, count, systemschema.SQLStatsHashShardBucketCount)
}
